{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7991317,"sourceType":"datasetVersion","datasetId":4704570}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pickle\nimport pandas as pd\nimport numpy as np\nfrom torch.utils.data import DataLoader, Dataset, TensorDataset\nimport math\nimport logging\nfrom datetime import datetime\nimport torch\nimport gzip\nfrom scipy.stats import pearsonr\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertTokenizer, BertModel, BertForSequenceClassification\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\ncriterion = torch.nn.MSELoss()","metadata":{"execution":{"iopub.status.busy":"2024-03-31T16:27:10.313036Z","iopub.execute_input":"2024-03-31T16:27:10.313433Z","iopub.status.idle":"2024-03-31T16:27:10.320538Z","shell.execute_reply.started":"2024-03-31T16:27:10.313399Z","shell.execute_reply":"2024-03-31T16:27:10.319520Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/nlpnlp1/bert_model.pkl', 'rb') as f:\n    loaded_model = pickle.load(f)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-31T16:18:13.025886Z","iopub.execute_input":"2024-03-31T16:18:13.027051Z","iopub.status.idle":"2024-03-31T16:18:13.529551Z","shell.execute_reply.started":"2024-03-31T16:18:13.027018Z","shell.execute_reply":"2024-03-31T16:18:13.528766Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def df_clean_test(df):\n    df_l = df.values.tolist()\n    df_new = []\n    c=0\n    for i in df_l:\n        # print(i)\n        c=0\n        for j in range(0,len(i)):\n\n            if('main-news' in str(i[j]) or 'main-forum' in str(i[j])):\n                # print(i)\n                c=1\n                continue\n        if(c==0):\n            if (pd.isnull(i[0]) or pd.isnull(i[1]) or pd.isnull(i[2])):\n                continue\n            df_new.append(i)\n    df_new = pd.DataFrame(df_new, columns = ['id','score','sentence1', 'sentence2'])\n    # df_new.to_csv('df_new.csv',index=False)\n    return df_new","metadata":{"execution":{"iopub.status.busy":"2024-03-31T16:18:15.566590Z","iopub.execute_input":"2024-03-31T16:18:15.567223Z","iopub.status.idle":"2024-03-31T16:18:15.574298Z","shell.execute_reply.started":"2024-03-31T16:18:15.567187Z","shell.execute_reply":"2024-03-31T16:18:15.573390Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"df_score = pd.read_csv('/kaggle/input/nlpnlp1/test_score.csv', delimiter='\\t')\n\n# df = pd.read_csv(pd.compat.StringIO(data), delimiter='\\t')df_score\ntest_score = df_score[['score']].values.tolist()\ntest_score","metadata":{"execution":{"iopub.status.busy":"2024-03-31T16:18:18.051116Z","iopub.execute_input":"2024-03-31T16:18:18.051543Z","iopub.status.idle":"2024-03-31T16:18:18.062180Z","shell.execute_reply.started":"2024-03-31T16:18:18.051509Z","shell.execute_reply":"2024-03-31T16:18:18.060917Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"[[5.0], [4.75], [5.0], [2.4], [2.75], [2.615]]"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('google-bert/bert-base-uncased')\n\ndef preprocess_data(sentences, scores):\n  encoded_inputs = []\n  for sent1, sent2 in sentences:\n    s = sent1 + sent2\n    encoded_dict = tokenizer(s, max_length=60, padding='max_length', truncation=True, return_tensors='pt')\n    encoded_inputs.append(encoded_dict)\n  return encoded_inputs, torch.tensor(scores, dtype=torch.float32)\n\n\ndef tokenize_data(sentences, scores):\n    input_ids = []\n    attention_masks = []\n    labels = []\n\n    for sentence_pair, score in zip(sentences, scores):\n        input_ids.append(sentence_pair['input_ids'].flatten())\n        attention_masks.append(sentence_pair['attention_mask'].flatten())\n        labels.append(torch.tensor(score, dtype=torch.float))\n\n    input_ids = torch.stack(input_ids).to(device)\n    attention_masks = torch.stack(attention_masks).to(device)\n    labels = torch.stack(labels).to(device)\n\n    return TensorDataset(input_ids, attention_masks, labels)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T16:21:02.824725Z","iopub.execute_input":"2024-03-31T16:21:02.825713Z","iopub.status.idle":"2024-03-31T16:21:02.939607Z","shell.execute_reply.started":"2024-03-31T16:21:02.825677Z","shell.execute_reply":"2024-03-31T16:21:02.938566Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"df_test = df_clean_test(pd.read_csv('/kaggle/input/nlpnlp1/sample_demo.csv', delimiter='\\t'))      #validation dataset\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntest_sentence = df_test[['sentence1', 'sentence2']].values.tolist()\nbatch_size = 8\ntest_sentence, test_score = preprocess_data(test_sentence, test_score)\ntest_dataset = tokenize_data(test_sentence, test_score)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)\n\n\nmodel = loaded_model\nrunning_val_loss = 0.0\npredictions = []\ntargets = []\nval_losses = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids, attention_mask, targets_batch = batch\n        input_ids, attention_mask, targets_batch = input_ids.to(device), attention_mask.to(device), targets_batch.to(device)\n#             targets_batch = targets_batch.view(-1, 1)  \n        targets.extend(targets_batch.cpu().numpy())\n\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        predictions.extend(outputs.logits.squeeze(-1).cpu().numpy())\n#             logits = np.array([(pred[0]+pred[1])/2 for pred in outputs.logits.squeeze(-1)]).reshape(-1)\n        logits = outputs.logits\n        logits = logits.mean(dim=1)\n        loss = criterion(logits, targets_batch)\n        running_val_loss += loss.item() * input_ids.size(0)\n\nepoch_val_loss = running_val_loss / len(test_dataset)\nval_losses.append(epoch_val_loss)\n\n#     print(predictions)\n#     print(targets)\npredictions = np.array([(pred[0]+pred[1])/2 for pred in predictions]).reshape(-1)\ntargets = np.array(targets).reshape(-1)\n\npearson_corr = np.corrcoef(predictions, targets)[0, 1]\nprint(f\"Test Loss: {epoch_val_loss:.4f}, Pearson Correlation: {pearson_corr:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-31T16:32:23.033460Z","iopub.execute_input":"2024-03-31T16:32:23.033858Z","iopub.status.idle":"2024-03-31T16:32:23.091870Z","shell.execute_reply.started":"2024-03-31T16:32:23.033805Z","shell.execute_reply":"2024-03-31T16:32:23.090841Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Test Loss: 2.4660, Pearson Correlation: 0.9929\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_34/46112322.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  return encoded_inputs, torch.tensor(scores, dtype=torch.float32)\n/tmp/ipykernel_34/46112322.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels.append(torch.tensor(score, dtype=torch.float))\n/opt/conda/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([6, 1])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  return F.mse_loss(input, target, reduction=self.reduction)\n","output_type":"stream"}]}]}