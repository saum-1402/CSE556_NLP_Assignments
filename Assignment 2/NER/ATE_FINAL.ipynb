{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfKZJordFLQL",
        "outputId": "f8daf7cb-bffa-4009-c126-f95d90ef1f3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1dxk9oMVvW4uJGB_SwoFUmweZ6BDOUinV   #lstm glove\n",
        "!gdown --id 17DjPVsM8IAb9nvIDV8RARhPtTKuIB0Lk   #gru glove\n",
        "!gdown --id 1qKVFSX2lO0rLdZgvGicish3mNFycxyOd   #rnn glove"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kgH5SQmNSi_",
        "outputId": "a54ca64b-cd3a-4195-907d-ce201bd6dd7f"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:138: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1dxk9oMVvW4uJGB_SwoFUmweZ6BDOUinV\n",
            "To: /content/ATElstmGlove.h5\n",
            "100% 11.0M/11.0M [00:00<00:00, 17.9MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:138: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17DjPVsM8IAb9nvIDV8RARhPtTKuIB0Lk\n",
            "To: /content/ATEgruGlove.h5\n",
            "100% 10.8M/10.8M [00:00<00:00, 16.7MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:138: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qKVFSX2lO0rLdZgvGicish3mNFycxyOd\n",
            "To: /content/ATErnnGlvoe.h5\n",
            "100% 10.2M/10.2M [00:00<00:00, 17.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id  1UqvL205fANIZ5RwIDx4bniof1nRC6usm   #lstm w2v\n",
        "!gdown --id  1jnGe5zaKFIMUjCSpwElfjwFya95B3P7g   #gru w2v\n",
        "!gdown --id  1nP9LAYZ-_pyvz-YljG-cZ8mjdqLGW5KX   #rnn w2v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6Ovc5ooR_hi",
        "outputId": "ac02356c-83c0-4a33-d738-b43bdd785e71"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:138: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1UqvL205fANIZ5RwIDx4bniof1nRC6usm\n",
            "To: /content/ATE_lstm_w2v.h5\n",
            "100% 11.0M/11.0M [00:00<00:00, 18.3MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:138: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1jnGe5zaKFIMUjCSpwElfjwFya95B3P7g\n",
            "To: /content/ATE_gru_w2v.h5\n",
            "100% 10.8M/10.8M [00:00<00:00, 17.0MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:138: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1nP9LAYZ-_pyvz-YljG-cZ8mjdqLGW5KX\n",
            "To: /content/ATE_rnn_w2v.h5\n",
            "100% 10.2M/10.2M [00:00<00:00, 25.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id  1cGFYQRiLSsC2KMKT9gwJVGEsg8ysyu-_  #lstm fasttext\n",
        "!gdown --id  1cYw5FmNjH7HvpGlbxx0TBaviy3eMhAdB  #gru fastext\n",
        "!gdown --id  1dHUb4futMXQTMkRO9izurARtzfTUXcKq  #rnn fastext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap2TY8zfSxbD",
        "outputId": "b58f9003-45e4-47ef-80ed-50979390f151"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:138: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cGFYQRiLSsC2KMKT9gwJVGEsg8ysyu-_\n",
            "To: /content/ATEFasttextLSTM.h5\n",
            "100% 11.0M/11.0M [00:00<00:00, 17.8MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:138: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cYw5FmNjH7HvpGlbxx0TBaviy3eMhAdB\n",
            "To: /content/ATEFasttextGRU.h5\n",
            "100% 10.8M/10.8M [00:00<00:00, 16.2MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:138: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1dHUb4futMXQTMkRO9izurARtzfTUXcKq\n",
            "To: /content/ATEFasttextRNN.h5\n",
            "100% 10.2M/10.2M [00:00<00:00, 17.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !gdown --id 1yH-U_Y9YdTdpQRBmDSgwXCNi-Fo0eMNv\n",
        "# !gdown --id 1PeZIwfzFFrSy2r6JD7kZLVJgavmaIJG1\n",
        "!gdown --id 1fK5XCdB_VZtha4wcuYrZ9h_e-Uk0EnwP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcIoTUCOKq4f",
        "outputId": "0213245e-a247-4d8b-a28c-49768135e5a8"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:138: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1fK5XCdB_VZtha4wcuYrZ9h_e-Uk0EnwP\n",
            "To: /content/ATE_test_data.json\n",
            "100% 142k/142k [00:00<00:00, 52.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from gensim.models import KeyedVectors# Load pre-trained model\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "import json\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import keras"
      ],
      "metadata": {
        "id": "gnjEWLsCMWcS"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=0)\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)), axis=0)\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)), axis=0)\n",
        "\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "\n",
        "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
        "\n",
        "    macro_f1 = K.mean(f1)\n",
        "    return macro_f1"
      ],
      "metadata": {
        "id": "xnb_xIsMOC66"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path_lstmglove = ('/content/ATElstmGlove.h5')\n",
        "model_path_rnnglove = ('/content/ATErnnGlvoe.h5')\n",
        "model_path_gruglove = ('/content/ATEgruGlove.h5')\n",
        "\n",
        "model_path_lstmw2v = ('/content/ATE_lstm_w2v.h5')\n",
        "model_path_rnnw2v = ('/content/ATE_rnn_w2v.h5')\n",
        "model_path_gruw2v = ('/content/ATE_gru_w2v.h5')\n",
        "# tf.keras.metrics.f1_m = f1_m\n",
        "# lstm_model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "model_path_lstmfast = ('/content/ATEFasttextLSTM.h5')\n",
        "model_path_rnnfast = ('/content/ATEFasttextRNN.h5')\n",
        "model_path_grufast = ('/content/ATEFasttextGRU.h5')\n",
        "\n",
        "lstmglove=keras.models.load_model(model_path_lstmglove, custom_objects={'f1_m': f1_m, 'precision_m': precision_m, 'recall_m': recall_m})\n",
        "rnnglove= keras.models.load_model(model_path_rnnglove, custom_objects={'f1_m': f1_m, 'precision_m': precision_m, 'recall_m': recall_m})\n",
        "gruglove = keras.models.load_model(model_path_gruglove, custom_objects={'f1_m': f1_m, 'precision_m': precision_m, 'recall_m': recall_m})\n",
        "lstmw2v = keras.models.load_model(model_path_lstmw2v, custom_objects={'f1_m': f1_m, 'precision_m': precision_m, 'recall_m': recall_m})\n",
        "rnnw2v = keras.models.load_model(model_path_rnnw2v, custom_objects={'f1_m': f1_m, 'precision_m': precision_m, 'recall_m': recall_m})\n",
        "gruw2v = keras.models.load_model(model_path_gruw2v, custom_objects={'f1_m': f1_m, 'precision_m': precision_m, 'recall_m': recall_m})\n",
        "lstmfast = keras.models.load_model(model_path_lstmfast, custom_objects={'f1_m': f1_m, 'precision_m': precision_m, 'recall_m': recall_m})\n",
        "rnnfast = keras.models.load_model(model_path_rnnfast, custom_objects={'f1_m': f1_m, 'precision_m': precision_m, 'recall_m': recall_m})\n",
        "grufast = keras.models.load_model(model_path_grufast, custom_objects={'f1_m': f1_m, 'precision_m': precision_m, 'recall_m': recall_m})"
      ],
      "metadata": {
        "id": "YceY1SCQFX6A"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "TQwI2HVnH_Ff"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_file_path = '/content/ATE_test_data.json'\n",
        "\n",
        "# Read the JSON file\n",
        "\n",
        "with open(json_file_path) as f:\n",
        "    test_data = json.load(f)"
      ],
      "metadata": {
        "id": "r9h2zxqIHtTR"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key, value in test_data.items():\n",
        "    word = value['text'].split(\" \")\n",
        "    labels = value['labels']\n",
        "    new_labels = []\n",
        "    new_word = []\n",
        "    for i in range(len(word)):\n",
        "        if(word[i]==''):\n",
        "            print(\"SADf\")\n",
        "            continue\n",
        "        new_word.append(word[i])\n",
        "    value['word'] = new_word"
      ],
      "metadata": {
        "id": "R_atDolLMJvs"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = []\n",
        "tags_for_testing = []\n",
        "sentence_for_testing = []\n",
        "for key, value in test_data.items():\n",
        "    word = value['word']\n",
        "    tags = value['labels']\n",
        "    sentence = value['text']\n",
        "    # Pad the entire sentence\n",
        "    # if len(word) < max_len:\n",
        "    #     word += [''] * (max_len - len(word))\n",
        "    #     tags += ['O'] * (max_len - len(tags))\n",
        "\n",
        "    sentence_for_testing.append(word)\n",
        "    tags_for_testing.append(tags)\n",
        "\n",
        "    # Tokenize the entire sentence\n",
        "    # tokenizer = Tokenizer()\n",
        "    # tokenizer.fit_on_texts([word])\n",
        "    X_test.append(word)\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_test)\n",
        "X_test_token = tokenizer.texts_to_sequences(X_test)\n",
        "X_test = pad_sequences(X_test_token,  maxlen= 78, padding='post', truncating='pre')\n",
        "X_test_n = pad_sequences(X_test_token,  maxlen= 100, padding='post', truncating='pre')"
      ],
      "metadata": {
        "id": "XeuNAwS0L53b"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenizer = Tokenizer()                      # instantiate tokeniser\n",
        "word_tokenizer.fit_on_texts(tags_for_testing)                    # fit tokeniser on data\n",
        "y_test = word_tokenizer.texts_to_sequences(tags_for_testing)  # use the tokeniser to encode input sequence\n",
        "\n",
        "\n",
        "# for i in range(len(y_test)):\n",
        "#     for j in range(len(y_test[i])):\n",
        "#         y_test[i][j]-=1\n",
        "\n",
        "y_test = pad_sequences(y_test,  maxlen= 78, padding='post', truncating='pre')\n",
        "y_test_n = pad_sequences(y_test,  maxlen= 100, padding='post', truncating='pre')\n",
        "y_test = to_categorical(y_test)\n",
        "y_test_n = to_categorical(y_test_n)"
      ],
      "metadata": {
        "id": "wrIZc9M8L7nc"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def evaluate_model(model,X_test,y_test):\n",
        "  results = model.evaluate(X_test,y_test, verbose = 1)\n",
        "  print(\"Loss: {0},\\nAccuracy: {1}\".format(results[0], results[1]))\n",
        "  y_pred = model.predict(X_test)\n",
        "  y_pred = np.argmax(y_pred, axis=-1)\n",
        "  y_test = np.argmax(y_test, axis=-1)\n",
        "  f1 = f1_score(y_test.flatten(), y_pred.flatten(), average='macro')\n",
        "  print(\"macro F1 score is :\", f1)\n",
        "  return"
      ],
      "metadata": {
        "id": "G2E7Al16PcOF"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"------------------------WORD2VEC----------------------------  \")\n",
        "\n",
        "print(\"LSTM Model:\")\n",
        "print(evaluate_model(lstmw2v,X_test_n,y_test_n))\n",
        "\n",
        "print(\"RNN Model\")\n",
        "print(evaluate_model(rnnw2v,X_test,y_test))\n",
        "\n",
        "print(\"GRU Model\")\n",
        "print(evaluate_model(gruw2v,X_test_n,y_test_n))\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"------------------------GLOVE---------------------------------  \")\n",
        "\n",
        "print(\"LSTM Model:\")\n",
        "print(evaluate_model(lstmglove,X_test_n,y_test_n))\n",
        "\n",
        "print(\"RNN Model\")\n",
        "print(evaluate_model(rnnglove,X_test,y_test))\n",
        "\n",
        "print(\"GRU Model\")\n",
        "print(evaluate_model(gruglove,X_test_n,y_test_n))\n",
        "\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"----------------------FASTTEXT--------------------------------  \")\n",
        "\n",
        "print(\"LSTM Model:\")\n",
        "print(evaluate_model(lstmfast,X_test_n,y_test_n))\n",
        "\n",
        "print(\"RNN Model\")\n",
        "print(evaluate_model(rnnfast,X_test,y_test))\n",
        "\n",
        "print(\"GRU Model\")\n",
        "print(evaluate_model(grufast,X_test_n,y_test_n))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYkAKN8uPvZT",
        "outputId": "f061b324-e75a-4c2e-da67-a0091ec87b77"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------WORD2VEC----------------------------  \n",
            "LSTM Model:\n",
            "11/11 [==============================] - 0s 40ms/step - loss: 0.1194 - acc: 0.9662 - f1_m: 0.3357 - precision_m: 0.9731 - recall_m: 0.9607\n",
            "Loss: 0.11939260363578796,\n",
            "Accuracy: 0.9661890268325806\n",
            "11/11 [==============================] - 0s 40ms/step\n",
            "macro F1 score is : 0.48218557036914106\n",
            "None\n",
            "RNN Model\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.1185 - acc: 0.9694 - f1_m: 0.3684 - precision_m: 0.9723 - recall_m: 0.9613\n",
            "Loss: 0.11853870749473572,\n",
            "Accuracy: 0.9693558216094971\n",
            "11/11 [==============================] - 0s 11ms/step\n",
            "macro F1 score is : 0.4973351162423099\n",
            "None\n",
            "GRU Model\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.0889 - acc: 0.9778 - f1_m: 0.3455 - precision_m: 0.9784 - recall_m: 0.9750\n",
            "Loss: 0.08887539803981781,\n",
            "Accuracy: 0.9777743816375732\n",
            "11/11 [==============================] - 0s 31ms/step\n",
            "macro F1 score is : 0.4841368328524795\n",
            "None\n",
            "\n",
            "------------------------GLOVE---------------------------------  \n",
            "LSTM Model:\n",
            "11/11 [==============================] - 0s 43ms/step - loss: 0.1368 - acc: 0.9555 - f1_m: 0.3220 - precision_m: 0.9601 - recall_m: 0.9507\n",
            "Loss: 0.1368323415517807,\n",
            "Accuracy: 0.955457329750061\n",
            "11/11 [==============================] - 0s 37ms/step\n",
            "macro F1 score is : 0.46490726705887164\n",
            "None\n",
            "RNN Model\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.1641 - acc: 0.9470 - f1_m: 0.3478 - precision_m: 0.9515 - recall_m: 0.9325\n",
            "Loss: 0.16410411894321442,\n",
            "Accuracy: 0.9469590187072754\n",
            "11/11 [==============================] - 0s 13ms/step\n",
            "macro F1 score is : 0.47317373335889584\n",
            "None\n",
            "GRU Model\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.1170 - acc: 0.9665 - f1_m: 0.3346 - precision_m: 0.9674 - recall_m: 0.9645\n",
            "Loss: 0.11696769297122955,\n",
            "Accuracy: 0.9664939045906067\n",
            "11/11 [==============================] - 1s 62ms/step\n",
            "macro F1 score is : 0.47409651813687886\n",
            "None\n",
            "\n",
            "----------------------FASTTEXT--------------------------------  \n",
            "LSTM Model:\n",
            "11/11 [==============================] - 1s 72ms/step - loss: 0.1604 - acc: 0.9645 - f1_m: 0.3370 - precision_m: 0.9695 - recall_m: 0.9600\n",
            "Loss: 0.16037042438983917,\n",
            "Accuracy: 0.9645426869392395\n",
            "11/11 [==============================] - 0s 37ms/step\n",
            "macro F1 score is : 0.4973169330352471\n",
            "None\n",
            "RNN Model\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.1183 - acc: 0.9650 - f1_m: 0.3648 - precision_m: 0.9723 - recall_m: 0.9576\n",
            "Loss: 0.11825689673423767,\n",
            "Accuracy: 0.9649780988693237\n",
            "11/11 [==============================] - 0s 12ms/step\n",
            "macro F1 score is : 0.48464183607562605\n",
            "None\n",
            "GRU Model\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.0900 - acc: 0.9765 - f1_m: 0.3442 - precision_m: 0.9785 - recall_m: 0.9724\n",
            "Loss: 0.08997688442468643,\n",
            "Accuracy: 0.9764634370803833\n",
            "11/11 [==============================] - 0s 33ms/step\n",
            "macro F1 score is : 0.48813743378644875\n",
            "None\n"
          ]
        }
      ]
    }
  ]
}